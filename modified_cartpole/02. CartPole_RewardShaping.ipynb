{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9174ae5a",
   "metadata": {},
   "source": [
    "# CartPole_RewardShaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ea28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import logger, spaces\n",
    "from gymnasium.envs.classic_control import utils\n",
    "from gymnasium.error import DependencyNotInstalled\n",
    "from gymnasium.experimental.vector import VectorEnv\n",
    "from gymnasium.vector.utils import batch_space\n",
    "from gymnasium.wrappers import TimeLimit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc844b4",
   "metadata": {},
   "source": [
    "# CartPole_RewardShaping Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eda59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleEnv_RewardShaping(gym.Env[np.ndarray, Union[int, np.ndarray]]):\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 50,\n",
    "    }\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = self.masspole + self.masscart\n",
    "        self.length = 0.5  # actually half the pole's length\n",
    "        self.polemass_length = self.masspole * self.length\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.kinematics_integrator = \"euler\"\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds.\n",
    "        high = np.array(\n",
    "            [\n",
    "                self.x_threshold * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "                self.theta_threshold_radians * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        # self.action_space = spaces.Discrete(2) Changed!!!\n",
    "        ##########\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        ##########\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.screen_width = 600\n",
    "        self.screen_height = 400\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.isopen = True\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_terminated = None\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(\n",
    "            action\n",
    "        ), f\"{action!r} ({type(action)}) invalid\"\n",
    "        assert self.state is not None, \"Call reset before using step method.\"\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        # force = self.force_mag if action == 1 else -self.force_mag Changed!!!\n",
    "        ##########\n",
    "        if action == 2:\n",
    "            force = 0\n",
    "        elif action == 1:\n",
    "            force = self.force_mag\n",
    "        else:\n",
    "            force = -self.force_mag\n",
    "        ##########\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "\n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        temp = (\n",
    "            force + self.polemass_length * theta_dot**2 * sintheta\n",
    "        ) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / (\n",
    "            self.length * (4.0 / 3.0 - self.masspole * costheta**2 / self.total_mass)\n",
    "        )\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "\n",
    "        if self.kinematics_integrator == \"euler\":\n",
    "            x = x + self.tau * x_dot\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "        else:  # semi-implicit euler\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            x = x + self.tau * x_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        terminated = bool(\n",
    "            x < -self.x_threshold\n",
    "            or x > self.x_threshold\n",
    "            or theta < -self.theta_threshold_radians\n",
    "            or theta > self.theta_threshold_radians\n",
    "        )\n",
    "\n",
    "        if not terminated:\n",
    "            reward = 1.0\n",
    "            ########## Added!!!\n",
    "            if action == 0 or action == 1:\n",
    "                reward -= 0.5\n",
    "            ##########\n",
    "        elif self.steps_beyond_terminated is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_terminated = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_terminated == 0:\n",
    "                logger.warn(\n",
    "                    \"You are calling 'step()' even though this \"\n",
    "                    \"environment has already returned terminated = True. You \"\n",
    "                    \"should always call 'reset()' once you receive 'terminated = \"\n",
    "                    \"True' -- any further steps are undefined behavior.\"\n",
    "                )\n",
    "            self.steps_beyond_terminated += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(self.state, dtype=np.float32), reward, terminated, False, {}\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        # Note that if you use custom reset bounds, it may lead to out-of-bound\n",
    "        # state/observations.\n",
    "        low, high = utils.maybe_parse_reset_bounds(\n",
    "            options, -0.05, 0.05  # default low\n",
    "        )  # default high\n",
    "        self.state = self.np_random.uniform(low=low, high=high, size=(4,))\n",
    "        self.steps_beyond_terminated = None\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(self.state, dtype=np.float32), {}\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            assert self.spec is not None\n",
    "            gym.logger.warn(\n",
    "                \"You are calling render method without specifying any render mode. \"\n",
    "                \"You can specify the render_mode at initialization, \"\n",
    "                f'e.g. gym.make(\"{self.spec.id}\", render_mode=\"rgb_array\")'\n",
    "            )\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            import pygame\n",
    "            from pygame import gfxdraw\n",
    "        except ImportError as e:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run `pip install gymnasium[classic-control]`\"\n",
    "            ) from e\n",
    "\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            if self.render_mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                self.screen = pygame.display.set_mode(\n",
    "                    (self.screen_width, self.screen_height)\n",
    "                )\n",
    "            else:  # mode == \"rgb_array\"\n",
    "                self.screen = pygame.Surface((self.screen_width, self.screen_height))\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        world_width = self.x_threshold * 2\n",
    "        scale = self.screen_width / world_width\n",
    "        polewidth = 10.0\n",
    "        polelen = scale * (2 * self.length)\n",
    "        cartwidth = 50.0\n",
    "        cartheight = 30.0\n",
    "\n",
    "        if self.state is None:\n",
    "            return None\n",
    "\n",
    "        x = self.state\n",
    "\n",
    "        self.surf = pygame.Surface((self.screen_width, self.screen_height))\n",
    "        self.surf.fill((255, 255, 255))\n",
    "\n",
    "        l, r, t, b = -cartwidth / 2, cartwidth / 2, cartheight / 2, -cartheight / 2\n",
    "        axleoffset = cartheight / 4.0\n",
    "        cartx = x[0] * scale + self.screen_width / 2.0  # MIDDLE OF CART\n",
    "        carty = 100  # TOP OF CART\n",
    "        cart_coords = [(l, b), (l, t), (r, t), (r, b)]\n",
    "        cart_coords = [(c[0] + cartx, c[1] + carty) for c in cart_coords]\n",
    "        gfxdraw.aapolygon(self.surf, cart_coords, (0, 0, 0))\n",
    "        gfxdraw.filled_polygon(self.surf, cart_coords, (0, 0, 0))\n",
    "\n",
    "        l, r, t, b = (\n",
    "            -polewidth / 2,\n",
    "            polewidth / 2,\n",
    "            polelen - polewidth / 2,\n",
    "            -polewidth / 2,\n",
    "        )\n",
    "\n",
    "        pole_coords = []\n",
    "        for coord in [(l, b), (l, t), (r, t), (r, b)]:\n",
    "            coord = pygame.math.Vector2(coord).rotate_rad(-x[2])\n",
    "            coord = (coord[0] + cartx, coord[1] + carty + axleoffset)\n",
    "            pole_coords.append(coord)\n",
    "        gfxdraw.aapolygon(self.surf, pole_coords, (202, 152, 101))\n",
    "        gfxdraw.filled_polygon(self.surf, pole_coords, (202, 152, 101))\n",
    "\n",
    "        gfxdraw.aacircle(\n",
    "            self.surf,\n",
    "            int(cartx),\n",
    "            int(carty + axleoffset),\n",
    "            int(polewidth / 2),\n",
    "            (129, 132, 203),\n",
    "        )\n",
    "        gfxdraw.filled_circle(\n",
    "            self.surf,\n",
    "            int(cartx),\n",
    "            int(carty + axleoffset),\n",
    "            int(polewidth / 2),\n",
    "            (129, 132, 203),\n",
    "        )\n",
    "\n",
    "        gfxdraw.hline(self.surf, 0, self.screen_width, carty, (0, 0, 0))\n",
    "\n",
    "        self.surf = pygame.transform.flip(self.surf, False, True)\n",
    "        self.screen.blit(self.surf, (0, 0))\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "            pygame.display.flip()\n",
    "\n",
    "        elif self.render_mode == \"rgb_array\":\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58972b3",
   "metadata": {},
   "source": [
    "# CartPole_RewardShaping Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70f8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3 import PPO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3066f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "result_dir = \"results\"\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd4defe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs/RewardShaping\n"
     ]
    }
   ],
   "source": [
    "model_rewardshaping_dir = f\"{model_dir}/RewardShaping\"\n",
    "if not os.path.exists(model_rewardshaping_dir):\n",
    "    os.makedirs(model_rewardshaping_dir)\n",
    "\n",
    "log_rewardshaping_dir = f\"{log_dir}/RewardShaping\"\n",
    "if not os.path.exists(log_rewardshaping_dir):\n",
    "    os.makedirs(log_rewardshaping_dir)\n",
    "\n",
    "result_rewardshaping_dir = f\"{result_dir}/RewardShaping\"\n",
    "if not os.path.exists(result_rewardshaping_dir):\n",
    "    os.makedirs(result_rewardshaping_dir)\n",
    "    \n",
    "logger_rewardshaping = configure(log_rewardshaping_dir, [\"stdout\", \"csv\", \"tensorboard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b1d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_train_rewardshaping = CartPoleEnv_RewardShaping()\n",
    "env_train_rewardshaping = TimeLimit(env_train_rewardshaping, max_episode_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7987a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.3     |\n",
      "|    ep_rew_mean     | 16.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 2133     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 25.4         |\n",
      "|    ep_rew_mean          | 17.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1457         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067037703 |\n",
      "|    clip_fraction        | 0.0692       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.00668      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.55         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35          |\n",
      "|    ep_rew_mean          | 24.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1276        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008972799 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.8        |\n",
      "|    ep_rew_mean          | 31.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1225        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012852833 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.05        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.2        |\n",
      "|    ep_rew_mean          | 38.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1197        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014796404 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 73.4       |\n",
      "|    ep_rew_mean          | 50.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1170       |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01267672 |\n",
      "|    clip_fraction        | 0.0844     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.984     |\n",
      "|    explained_variance   | 0.524      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.09       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    value_loss           | 24.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 90.7        |\n",
      "|    ep_rew_mean          | 62.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1149        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008238016 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.49        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 107          |\n",
      "|    ep_rew_mean          | 73.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1141         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049625826 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.997       |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.43         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 124          |\n",
      "|    ep_rew_mean          | 86.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1141         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061838967 |\n",
      "|    clip_fraction        | 0.0597       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.964       |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.6          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1141        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011403431 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.953      |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    value_loss           | 4.9         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1141        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014363999 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 6.05        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 177          |\n",
      "|    ep_rew_mean          | 128          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1142         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089067165 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.848       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.707        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00873     |\n",
      "|    value_loss           | 5.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 141         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1143        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010694495 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.803      |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.01        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 210        |\n",
      "|    ep_rew_mean          | 156        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1137       |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00646899 |\n",
      "|    clip_fraction        | 0.0497     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.761     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.6       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.00459   |\n",
      "|    value_loss           | 35.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 230         |\n",
      "|    ep_rew_mean          | 174         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1131        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008105707 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | 187         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1130        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010256803 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | 205          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1126         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032140198 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.65        |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | 219         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1125        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003372938 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 296          |\n",
      "|    ep_rew_mean          | 234          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1125         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030578477 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.603       |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 311         |\n",
      "|    ep_rew_mean          | 249         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1126        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010592389 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.35        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 7.08        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 326         |\n",
      "|    ep_rew_mean          | 263         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1127        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011327798 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.539      |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.883       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 2.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 277         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1126        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009621091 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.508      |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.257       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 290         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1122        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011510398 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.196       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    value_loss           | 0.763       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | 303         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1121        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003937578 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.84        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 9.6         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 368          |\n",
      "|    ep_rew_mean          | 312          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1122         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055477815 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.276       |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0614       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    value_loss           | 0.428        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 384         |\n",
      "|    ep_rew_mean          | 330         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1122        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002509078 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    value_loss           | 0.683       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 394          |\n",
      "|    ep_rew_mean          | 342          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1123         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054065017 |\n",
      "|    clip_fraction        | 0.0547       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.242       |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00753     |\n",
      "|    value_loss           | 0.284        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 404          |\n",
      "|    ep_rew_mean          | 354          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1123         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072553447 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.195       |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0945       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    value_loss           | 0.238        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 411          |\n",
      "|    ep_rew_mean          | 364          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1123         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028274315 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.151       |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0327       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    value_loss           | 0.207        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 420        |\n",
      "|    ep_rew_mean          | 376        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1123       |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00565407 |\n",
      "|    clip_fraction        | 0.0474     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.203     |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0675     |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0045    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 425        |\n",
      "|    ep_rew_mean          | 384        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1121       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01971127 |\n",
      "|    clip_fraction        | 0.0926     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.203     |\n",
      "|    explained_variance   | 0.855      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.00712   |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 429         |\n",
      "|    ep_rew_mean          | 391         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1119        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001926963 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 439          |\n",
      "|    ep_rew_mean          | 402          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1118         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052447272 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0292       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 0.0742       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 446          |\n",
      "|    ep_rew_mean          | 411          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1119         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060460577 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.14        |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0056       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 0.0595       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 452          |\n",
      "|    ep_rew_mean          | 419          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1119         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016052072 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.111       |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0222       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 0.0657       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 459          |\n",
      "|    ep_rew_mean          | 428          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1119         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029050303 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.114       |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00856      |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 0.0464       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 463          |\n",
      "|    ep_rew_mean          | 435          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1120         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014624388 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0978      |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0163       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 0.0562       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 470          |\n",
      "|    ep_rew_mean          | 443          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1120         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016290043 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0964      |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0217       |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 0.038        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 478          |\n",
      "|    ep_rew_mean          | 452          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1121         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016357854 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0944      |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0142       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 0.0352       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 485          |\n",
      "|    ep_rew_mean          | 460          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1120         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026911672 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.098       |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0173       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 0.0523       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 489          |\n",
      "|    ep_rew_mean          | 466          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1119         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006864169 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0775      |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0276       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 0.0292       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 494          |\n",
      "|    ep_rew_mean          | 473          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1117         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010413197 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0775      |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0349       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000155    |\n",
      "|    value_loss           | 0.0356       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | 476          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1117         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021057883 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0589      |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00327     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    value_loss           | 0.0438       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | 478          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1117         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006912238 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0723      |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00729      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000342    |\n",
      "|    value_loss           | 0.0173       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | 480          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1117         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012412064 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0643      |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00728      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | 0.000264     |\n",
      "|    value_loss           | 0.0241       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | 482          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1117         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005593031 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0728      |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00106      |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 0.00128      |\n",
      "|    value_loss           | 0.0155       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 487          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1118         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005657398 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0685      |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0144       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    value_loss           | 0.021        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 487         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1118        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000359233 |\n",
      "|    clip_fraction        | 0.00522     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0668     |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00644     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 0.026       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 488          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1115         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014136038 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0649      |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00331      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.000416    |\n",
      "|    value_loss           | 0.0237       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x21277b677c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rewardshaping = PPO(\"MlpPolicy\", env_train_rewardshaping, verbose=1)\n",
    "model_rewardshaping.set_logger(logger_rewardshaping)\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=2048, save_path=model_rewardshaping_dir)\n",
    "model_rewardshaping.learn(100000, callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e2b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_train_rewardshaping.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0bb7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_learning_data_rewardshaping = pd.read_csv(\"logs/rewardshaping/progress.csv\")\n",
    "model_id_best_rewardshaping = (model_learning_data_rewardshaping[\"rollout/ep_rew_mean\"].idxmax() + 1) * 2048\n",
    "model_path_best_rewardshaping = f\"{model_rewardshaping_dir}/rl_model_{model_id_best_rewardshaping}_steps.zip\"\n",
    "model_best_rewardshaping = PPO.load(model_path_best_rewardshaping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d10be",
   "metadata": {},
   "source": [
    "# CartPole_RewardShaping Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f981a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test_rewardshaping = CartPoleEnv_RewardShaping()\n",
    "env_test_rewardshaping = TimeLimit(env_test_rewardshaping, max_episode_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e39512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_rewardshaping = []\n",
    "rewards_rewardshaping = []\n",
    "steps_rewardshaping = []\n",
    "\n",
    "for i in range(100):\n",
    "    step = 0\n",
    "    score = 0\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "    observation, info = env_test_rewardshaping.reset(seed=100+i)\n",
    "\n",
    "    while not terminated and not truncated:\n",
    "        action = model_best_rewardshaping.predict(observation)[0]\n",
    "        observation, reward, terminated, truncated, info = env_test_rewardshaping.step(action)\n",
    "        \n",
    "        score += reward\n",
    "        step += 1\n",
    "        actions_rewardshaping.append(int(action))\n",
    "        \n",
    "    rewards_rewardshaping.append(score)\n",
    "    steps_rewardshaping.append(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca32a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test_rewardshaping.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40361282",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{result_rewardshaping_dir}/rewards_rewardshaping.txt\", rewards_rewardshaping)\n",
    "np.savetxt(f\"{result_rewardshaping_dir}/steps_rewardshaping.txt\", steps_rewardshaping)\n",
    "np.savetxt(f\"{result_rewardshaping_dir}/actions_rewardshaping.txt\", actions_rewardshaping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb56f249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
